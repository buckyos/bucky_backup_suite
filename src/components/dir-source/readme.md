## 需求：
1. 给定目录运行扫描，最终得到目录的Hash值(目录Hash值的计算类似git的Tree Object)。
2. 扫描过程中，可以先假设目录此时只读的，不需要处理已经扫描过的文件发送变化的异常
3. 扫描的过程可以随时暂停和恢复，扫描的过程保存在一个用sqlite数据库中、为了提高IO性能，该sqlite数据库可以是基于文件映射的内存数据库，不必每次都落盘
4. 计算文件hash的过程中，如果文件特别大，则进入一个专门的，可恢复的大文件hash计算队列。大文件的hash计算也是可中断和可恢复的。
5. 扫描开始时可能会给出一个“上一次扫描”完成得到的sqlite数据库，当出现相同文件时，有可能需要进行diff计算（留好接口即可，现在不用实现diff）
6. 实现要尽量提高IO性能，减少临时磁盘空间的使用和内存使用
7. 目标目录可能非常大(>1000GB),有海量文件。
8. 扫描前有类似gitignore的配置，可以跳过特定的目录或文件
9. 在扫描开始时，输入一个可选的“操作日志”，操作日志由目录监控软件产生。随后在扫描的过程中可以依赖该日志来提高性能。需要注意的是操作日志可能也非常的大，因此必须保存在sqlite中。需要注意的是，目录监控软件已经完成了操作日志的有效性校验，比如如果一个文件夹已经被删除了，那么之前该文件内的各种修改操作都不会出现在输入的操作日志中。 
10. 正确处理 LINk： 如果软连接指向的文件路径在“根目录下” （可以在扫描时指定），则保存相对路径（这样可以影响目录的Hash）。硬连接就当标准的文件处理。
11. 正确处理文件的重要属性信息（元信息），在操作系统提供的元信息中提取出有效元信息，有效元信息的修改会影响文件夹的Hash计算


## 利用 Backup 和 Restore 操作来实现同步

1. 每个设备都定期调用Restore操作
2. 每个设备都定期调用Backup操作。
3. 当Backup操作发起时，如果服务器的上的版本更领先，则
    方案一、和GIT一样，先执行一次“一定成功”的自动合并操作，在执行Backup
    方案二（我们的选择）、由服务器执行一次一定“会成功”的自动合并操作，在执行完成Backup后立刻执行一次Restore

    方案二的优点是对只需要升级服务器的软件，即可不断应用更新的自动合并行为。能保持客户端内核的相对稳定。而且服务器的资源更多，能提供更强力的合并支持。


## engine的可扩展性边界：

1. Source部分在Dir上没什么好扩展的，最多是扩展FS的实现（但依旧提供了文件夹的标准接口）。目前的实现，刻意回避了文件系统的高级功能
2. Source部分在Chunk上很好扩展，本质上应用可以扩展Chunk构建器，易于与我们的系统对接（从心理上说，这种直接对接的方式比基于文件系统对接要更可靠）
3.  
